## 执行抓取工作的线程数量
crawler.property.worker.count=10

## 当工作线程获取不到待抓取的urls时，线程休眠时间，单位：毫秒
crawler.property.sleepTimeNoneUrls=5000

## 每次从Controller层批量拉取url数量，然后填充到本地缓存队列中
crawler.property.documentInputCount=1000
## 工作线程每次从本地缓存队列中批量获取url数量
crawler.property.documentOutputCount=20
## Crawler端从Controller端定时拉取任务配置的时间间隔
crawler.property.taskReloadFetchInterval=10000
## Crawler端向Controller端定时发送心跳信息的时间间隔
crawler.property.heartbeatInterval=6000
## Crawler端从Controller端定时拉取代理IPs的时间间隔
crawler.property.proxyFetchInterval=60000
## 最近连续多少次抓取失败则删除Url
crawler.property.deleteThresholdOnCrawledFailedTimes=5

## Thrift连接时的属性配置
crawler.property.thrift.serviceIP=10.25.169.237
crawler.property.thrift.servicePort=7911
crawler.property.thrift.connectTimeOut=30000
crawler.property.thrift.initialBufferCapacity=10240
crawler.property.thrift.maxLength=1024000

crawler.property.tempoInterval=10000


##upyun 服务  操作员信息
upyun.bucketName=st-prod
upyun.userName=shantao
upyun.password=qDnnAdOTfpoWc
upyun.address=http://st-prod.b0.upaiyun.com


##kafka
kafka.haitao.topic=spider_55haitao_product
#kafka producer config
kafka.bootstrap.servers=10.24.32.17:9092,10.45.22.63:9093
kafka.acks=all
kafka.retries=3
kafka.batch.size=16384
kafka.linger.ms=1
kafka.buffer.memory=33554432
kafka.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.value.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.max.request.size=10485760
##kafka consumer config


##redis
redis.host=redis://:spider55haitao@10.24.32.17:12002

## 返利网合作支持功能中的邮件相关配置
fanli.support.email.send.interval=3600000
fanli.support.email.sender.address=guanwangzhigou@55haitao.com
fanli.support.email.sender.password=55HaiTao
fanli.support.email.receiver.addresses=lan.jia@fanli.com,zhangnan@fanli.com,zhaokongjun@linkhaitao.com,liqiang@55haitao.com,liushizhen@55haitao.com,chengna@55haitao.com,chenweilan@linkhaitao.com,qijun.ni@fanli.com,huifen.lu@fanli.com,junying.wang@fanli.com,liuhailiang@linkhaitao.com
##mongo config
mongo.host=10.128.0.2
mongo.port=27017
mongo.dbname=spider_55haitao
mongo.user=
mongo.passwd=
#########